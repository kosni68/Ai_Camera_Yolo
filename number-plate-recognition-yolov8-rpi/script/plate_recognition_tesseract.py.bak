import cv2
from picamera2 import Picamera2
from ultralytics import YOLO
import pytesseract
import numpy as np
import time
import re

def sharpen_image(image):
    kernel = np.array([[-1, -1, -1], [-1, 9,-1], [-1, -1, -1]])  # Simple sharpening kernel
    return cv2.filter2D(image, -1, kernel)

def preprocess_for_ocr(image):
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    gray = cv2.resize(gray, (0, 0), fx=2, fy=2)  # Upscale
    blur = cv2.GaussianBlur(gray, (5, 5), 0)  # Gaussian blur
    # Alternatively, you could try other denoising techniques
    denoised = cv2.fastNlMeansDenoising(gray, None, 30, 7, 21)
    thresh = cv2.adaptiveThreshold(
        denoised, 255,
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY_INV,
        11, 2
    )
    return thresh

def is_french_plate(text):
    clean = text.replace(" ", "").replace("-", "").upper()
    pattern = r'^([A-Z]{2}\d{3}[A-Z]{2}|\d{4}[A-Z]{2}\d{2}|\d{3}[A-Z]{2}\d{2})$'
    return re.match(pattern, clean) is not None

def format_french_plate(text):
    clean = text.replace(" ", "").replace("-", "").upper()
    # Format AA123AA ? AA-123-AA
    if re.match(r'^[A-Z]{2}\d{3}[A-Z]{2}$', clean):
        return f"{clean[:2]}-{clean[2:5]}-{clean[5:]}"
    # Format 1234AB56 ? 1234 AB 56
    elif re.match(r'^\d{4}[A-Z]{2}\d{2}$', clean):
        return f"{clean[:4]} {clean[4:6]} {clean[6:]}"
    # Format 123AB45 ? 123 AB 45
    elif re.match(r'^\d{3}[A-Z]{2}\d{2}$', clean):
        return f"{clean[:3]} {clean[3:5]} {clean[5:]}"
    else:
        return text  # Return original if no known format

# --- Component Initialization ---

def initialize_camera():
    camera = Picamera2()
    camera.preview_configuration.main.size = (1280, 720)
    camera.preview_configuration.main.format = "RGB888"
    camera.preview_configuration.align()
    camera.configure("preview")
    camera.start()
    return camera

def load_yolo_model():
    print("Loading YOLO NCNN model...")
    return YOLO("./models/license_plate_detector_ncnn_model")

# --- OCR with Tesseract ---

def run_tesseract_ocr(image):
    # Convert to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    #gray = preprocess_for_ocr(image)
    #gray = sharpen_image(image)

    # Resize for better OCR accuracy
    resized = cv2.resize(gray, (0, 0), fx=2, fy=2)

    # Tesseract config: OEM 3 (default), PSM 7 (single line)
    #custom_config = r'--oem 3 --psm 7'
    custom_config = r'--psm 7 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'

    
    print("Running OCR with Tesseract")
    text = pytesseract.image_to_string(resized, config=custom_config)
    return text.strip()

# --- Main Processing Loop ---

def main():
    camera = initialize_camera()
    model = load_yolo_model()

    # Open file to log detected plates
    log_file_path = "./data/detected_plates.txt"
    
    # Open file to log FPS stats
    fps_log_file_path = "./data/fps_stats.txt"
    fps_log_interval = 10  # seconds
    last_fps_log_time = time.time()
    
    fps_history = []   
    last_plate = None
    
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec MP4
    video_output_path = "./data/raw_video.mp4"
    frame_width = 1280
    frame_height = 720
    out = cv2.VideoWriter(video_output_path, fourcc, 20.0, (frame_width, frame_height))


    with open(log_file_path, "a") as log_file, open(fps_log_file_path, "a") as fps_log_file:

        while True:
            print("Capturing image")
            frame = camera.capture_array()
            
            # Rotate the frame by 180 degrees
            frame = cv2.rotate(frame, cv2.ROTATE_180)
            
            # Write the raw frame to video
            #out.write(frame)

            print("Running YOLO prediction")
            results = model.predict(frame, imgsz=320)[0]
            annotated_frame = results.plot()

            for box in results.boxes:
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                plate_crop = frame[y1:y2, x1:x2]

                if plate_crop.size == 0:
                    continue

                text = run_tesseract_ocr(plate_crop)
                if text:
                    if is_french_plate(text):
                        formatted = format_french_plate(text)
                        if formatted != last_plate:
                            print(f"[VALID] French plate detected: {formatted}")
                            last_plate = formatted

                            # Write to log
                            timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
                            log_file.write(f"[{timestamp}] {formatted}\n")
                            log_file.flush()

                        # Draw text below the rectangle
                        cv2.putText(
                            annotated_frame,
                            formatted,
                            (x1, y2 + 30),  # BELOW the bounding box
                            cv2.FONT_HERSHEY_SIMPLEX,
                            0.9,
                            (0, 255, 0),
                            2
                        )
                    else:
                        print(f"[IGNORED] Non-French plate format: {text}")

            inference_time = results.speed.get("inference", 1)
            fps = 1000 / inference_time
            fps_history.append(fps)

            # Keep the list short to avoid memory overflow
            if len(fps_history) > 1000:
                fps_history.pop(0)

            min_fps = min(fps_history)
            max_fps = max(fps_history)
            
            # Log FPS every 10 seconds
            current_time = time.time()
            if current_time - last_fps_log_time >= fps_log_interval:
                timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
                fps_log_file.write(f"[{timestamp}] Min FPS: {min_fps:.1f} | Max FPS: {max_fps:.1f}\n")
                fps_log_file.flush()

                # Reset FPS history
                fps_history = []
                last_fps_log_time = current_time

            fps_text = f"FPS: {fps:.1f} | Min: {min_fps:.1f} | Max: {max_fps:.1f}"
            
            # Dimensions du texte
            (text_width, text_height), _ = cv2.getTextSize(fps_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
            x, y = annotated_frame.shape[1] - 450, 30

            # Dessiner un fond rectangulaire legerement plus grand
            cv2.rectangle(
                annotated_frame,
                (x - 10, y - text_height - 10),
                (x + text_width + 10, y + 10),
                (0, 0, 0),  # noir
                -1  # -1 pour remplir le rectangle
            )

            # Afficher le texte par-dessus
            cv2.putText(
                annotated_frame,
                fps_text,
                (x, y),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (0, 255, 0),
                2
            )

            cv2.imshow("Camera", annotated_frame)

            if cv2.waitKey(1) & 0xFF == ord("q"):
                break

    cv2.destroyAllWindows()

# --- Entry Point ---
if __name__ == "__main__":
    main()
